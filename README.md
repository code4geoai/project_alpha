NDVI GUIDED LOW RANK ADAPTATION (LORA) OF  SEGMENT ANYTHING (SAM) FOR AGRICULTURE FIELDS BOUNDARY SEGMENTATION FROM SENTINEL 2 IMAGERY

INTRODUCTION:
Accurate delineation of agricultural field boundaries is foundational for crop monitoring , precision  agriculture, and land resource management [1], [2]. Multispectral satellite imagery such as  Sentinel-2 (10 m) provides globally consistent coverage at no per scene cost, making it attractive for large scale field mapping [3], [4].However, the coarse spatial sampling of Sentinel-2 and the irregular, often narrow parcels found in smallholder systems produce blurred or fragmented parcel edges , limiting reliable boundary extraction from RGB composite along [5], [6] .
Classical and modern pixel-wise methods (e.g., Random Forest, U-Net, DeepLab) obtain strong mask accuracy when dense labels and high-resolution inputs are available, but they require region-specific retraining and often fail to generalize across agro ecological zones and crop phenologies [7],[8]. Large annotated benchmarks such as Fields of the World (FTW) provide essential cross country testbeds for Sentinel-2 boundary segmentation, and AI4Boundaries uniquely pairs 1 m orthophotos with Sentinel-2 mosaics to quantify the fundamental resolution limits of 10 m products for parcel delineation  [5],[9]. These dataset studies show two recurring constraints: (1) many smallholder parcels fall below the minimum resolvable width for reliable 10 m delineation, and (2) models trained on one region commonly degrade when applied elsewhere.
Foundation vision models  particularly  Segment Anything Model (SAM) introduced a large, promptable segmentation paradigm that achieves remarkable zero-shot generalization on natural images [9]. Direct application of SAM to remote sensing is, however, challenged by modality gaps (spectral channels, spatial scale, and fine-grained boundaries) and by object definitions that differ from natural scenes [10],[11]. Recent adaptations have pursued complementary strategies: prompt diversification (GeoSAM) and prompt optimization for farmland (fabSAM), frequency-domain priors for edge sensitivity (RSAM-Seg), and efficient parameter adapters such as LoRA for aerial land-cover tasks [12], [13], [14]. To date, most adaptations exploit geometric or frequency cues; few explicitly inject spectral vegetation priors (e.g., NDVI) into the prompt or adaptation pipeline.
In this work we introduce an NDVI-Guided Low-Rank Adaptation of SAM for Sentinel-2 field boundary delineation. NDVI-guided prompting localizes candidate regions, while LoRA adapts SAM’s mask decoder to correctly interpret multispectral boundary cues, improving boundary continuity and robustness across regions. Our method (i) automatically extracts NDVI based spectral priors from Sentinel-2 time-series, (ii) converts those priors into structured prompt sets (superpixel centroids and boundary bands) to guide SAM, and (iii) performs lightweight LoRA fine tuning on large field FTW subsets to align SAM’s mask decoder with multispectral signals. We evaluate performance using both mask IoU and boundary-oriented metrics (Boundary F1 and mean boundary distance) across multiple FTW regions and on AI4Boundaries testcases where orthophoto comparisons are available. Our experiments quantify how NDVI prompts and LoRA adaptation improve boundary continuity and cross-region generalization while keeping compute and data costs low.
 2. Related Work
2.1 Datasets & Benchmarks for Agricultural Field Delineation
Large scale annotated datasets have been critical enablers for training and benchmarking field boundary delineation models. The Fields of the World (FTW) dataset provides globally distributed field boundary masks across 24 countries and diverse agro-ecological contexts, enabling cross region transfer studies using Sentinel-2 imagery [FTW]. Similarly, the FieldSeg dataset (built on Sentinel-2) established practical guidelines for field size thresholds and delineation performance under coarse resolution [FieldSeg]. In addition to that the AI4Boundaries dataset [AI4B] further highlighted the spatial resolution limitations of Sentinel-2 for parcel extraction by benchmarking 1 m orthophotos against Sentinel-2 mosaics over European and African agricultural landscapes. These benchmarks highlight two major constraints: many smallholder plots lie below the minimum viable size for reliable segmentation, and models trained on one region degrade when applied to another.
2.2 Classical Segmentation Methods and Transfer Learning
Prior to foundation model approaches, field boundary extraction relied on classical machine learning or deep learning frameworks such as Random Forest, UNet [Ronneberger et al., 2015], and DeepLab [Chen et al., 2018]. These architectures achieve good pixel level accuracy when extensive training data is available, but often require dense labels and lack robustness when transferred across crop types or geographies [Cheng et al., 2020]. Furthermore, they typically exploit spatial context in RGB images while under leveraging the rich multispectral signals available in agricultural domains.
2.3 Foundation Models for Remote-Sensing Segmentation
The publication of the Segment Anything Model (SAM) (Kirillov et al., 2023) introduced a generic prompt based segmentation paradigm with zero shot capability. However, SAM’s direct application to remote sensing data is challenged by differences in spectral composition, spatial scale, and object granularity [Kirillov et al., 2023; Xue et al., 2024]. Subsequent works adapted SAM for geospatial tasks:
•	GeoSAM employed multi-modal prompts (text + visual) to segment roads and pedestrian pathways in aerial imagery, demonstrating the feasibility of prompt diversification [GeoSAM].
•	fabSAM explored optimized prompt generation for farmland delineation, yet primarily focused on geometric cues and did not integrate spectral vegetation indices [fabSAM].
•	RSAM Seg fused frequency domain features via Fourier transforms to enhance edge sensitivity in remote sensing imagery, addressing boundary alignment more than domain adaptation [RSAM-Seg].
•	Two fine tuning paradigms emerged: low rank adaptation (LoRA) for efficient SAM retrieval [Xue et al., 2024], and multi-stage prefix/postfix adaptation pipelines for multispectral inputs [Song et al., 2024]. Despite these advances, none yet integrate spectral vegetation indices (such as NDVI) as guiding prompts in the SAM workflow.
2.4 Spectral Priors and NDVI in Field Boundary Delineation
Vegetation indices such as the Normalized Difference Vegetation Index (NDVI) provide robust proxies for crop vigour and canopy cover, and have been widely employed in agricultural remote sensing tasks. Their ability to differentiate crop vs non crop contrasts makes them a compelling candidate for boundary localization in agricultural mosaics. However, within the SAM adaptation literature, spectral indices are seldom used as prompt signals or fused embeddings. By contrast, adaptations such as RSAM Seg focus on frequency/texture cues and those such as FieldSeg emphasise mosaic size and layout, leaving a clear opening for NDVI guided prompt strategies.
2.5 Efficiency, Data Cost and Operational Scalability
Practical deployment of field delineation techniques hinges not only on segmentation accuracy but also on data cost, computational efficiency and domain generalizability. Methods such as FastSAM (2023) prioritize inference speed by replacing transformer backbones with lightweight CNNs, yet do not address domain spectral adaptation. Large-scale systems using high-resolution commercial imagery (e.g., <3 m planners in India) achieve high accuracy but come with prohibitive data acquisition costs and limited update frequency. In contrast, the proposed NDVI Guided LoRA SAM approach leverages free Sentinel-2 data, fine tunes SAM efficiently and embeds spectral priors for better cross region transfer.


[1]	S. Talukdar et al., “Land-use land-cover classification by machine learning classifiers for satellite observations-A review,” Apr. 01, 2020, MDPI AG. doi: 10.3390/rs12071135.
[2]	F. Waldner and F. I. Diakogiannis, “Deep learning on edge: Extracting field boundaries from satellite images with a convolutional neural network,” Remote Sens Environ, vol. 245, p. 111741, Aug. 2020, doi: 10.1016/J.RSE.2020.111741.
[3]	M. Drusch, U. Del Bello, S. Carlier, … O. C.-R. sensing of, and undefined 2012, “Sentinel-2: ESA’s optical high-resolution mission for GMES operational services,” Elsevier, 2012, Accessed: Sep. 18, 2025. [Online]. Available: https://www.sciencedirect.com/science/article/pii/S0034425712000636
[4]	M. Lesiv et al., “Estimating the global distribution of field size using crowdsourcing,” Glob Chang Biol, vol. 25, no. 1, pp. 174–186, Jan. 2019, doi: 10.1111/GCB.14492;CTYPE:STRING:JOURNAL.
[5]	H. Kerner et al., “Fields of The World: A Machine Learning Benchmark Dataset for Global Agricultural Field Boundary Segmentation,” Proceedings of the AAAI Conference on Artificial Intelligence, vol. 39, no. 27, pp. 28151–28159, Apr. 2025, doi: 10.1609/AAAI.V39I27.35034.
[6]	L. B. Ferreira, V. S. Martins, U. R. V. Aires, N. Wijewardane, X. Zhang, and S. Samiappan, “FieldSeg: A scalable agricultural field extraction framework based on the Segment Anything Model and 10-m Sentinel-2 imagery,” Comput Electron Agric, vol. 232, p. 110086, May 2025, doi: 10.1016/J.COMPAG.2025.110086.
[7]	O. Ronneberger, P. Fischer, and T. Brox, “U-Net: Convolutional Networks for Biomedical Image Segmentation,” May 2015, [Online]. Available: http://arxiv.org/abs/1505.04597
[8]	L. C. Chen, G. Papandreou, I. Kokkinos, K. Murphy, and A. L. Yuille, “DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs,” IEEE Trans Pattern Anal Mach Intell, vol. 40, no. 4, pp. 834–848, Apr. 2018, doi: 10.1109/TPAMI.2017.2699184.
[9]	R. D’andrimont et al., “AI4Boundaries: an open AI-ready dataset to map field boundaries with Sentinel-2 and aerial photography,” Earth Syst Sci Data, vol. 15, no. 1, pp. 317–329, Jan. 2023, doi: 10.5194/essd-15-317-2023.
[10]	A. Kirillov, E. Mintun, N. Ravi, … H. M.-P. of the, and undefined 2023, “Segment anything,” openaccess.thecvf.com, Accessed: Nov. 11, 2025. [Online]. Available: http://openaccess.thecvf.com/content/ICCV2023/html/Kirillov_Segment_Anything_ICCV_2023_paper.html
[11]	B. Xue, H. Cheng, Q. Yang, … Y. W.-I. G. and, and undefined 2024, “Adapting segment anything model to aerial land cover classification with low-rank adaptation,” ieeexplore.ieee.orgB Xue, H Cheng, Q Yang, Y Wang, X HeIEEE Geoscience and Remote Sensing Letters, 2024•ieeexplore.ieee.org, Accessed: Nov. 11, 2025. [Online]. Available: https://ieeexplore.ieee.org/abstract/document/10412208/
[12]	B. Song, H. Yang, Y. Wu, … P. Z.-I. T. on, and undefined 2024, “A multispectral remote sensing crop segmentation method based on segment anything model using multistage adaptation fine-tuning,” ieeexplore.ieee.orgB Song, H Yang, Y Wu, P Zhang, B Wang, G HanIEEE Transactions on Geoscience and Remote Sensing, 2024•ieeexplore.ieee.org, Accessed: Nov. 11, 2025. [Online]. Available: https://ieeexplore.ieee.org/abstract/document/10551868/
[13]	R. I. Sultan, D. Zhu, C. Li, H. Zhu, P. Khanduri, and M. Brocanelli, “GeoSAM: Fine-tuning SAM with Multi-Modal Prompts for Mobility Infrastructure Segmentation”, doi: 10.48550/arXiv.2311.11319.
[14]	Y. Xie et al., “fabSAM: A Farmland Boundary Delineation Method Based on the Segment Anything Model.”
 
